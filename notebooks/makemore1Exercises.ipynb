{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSlT5SUYO0H6CaN0oGHiXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benteaux/karpathy-tutorials/blob/main/notebooks/makemore1Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E01: Train a Trigram Language Model**"
      ],
      "metadata": {
        "id": "pod7QKKW-qdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZycP12Iu4AD"
      },
      "outputs": [],
      "source": [
        "# make a trigram - both counting & with neural nets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = open(\"names.txt\", \"r\").read().splitlines()"
      ],
      "metadata": {
        "id": "KskiPWgQvAv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "zIVh43LPvGxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros(729, 27).int()"
      ],
      "metadata": {
        "id": "wFt5NycXvKkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = sorted(list(set('.'.join(names))))"
      ],
      "metadata": {
        "id": "ipTQurOkvsf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "stoi = {}\n",
        "for let1 in (alphabet):\n",
        "  for let2 in (alphabet):\n",
        "    stoi[let1+let2] = i\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "rqtaVL3Kv2Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = {i:s for s, i in stoi.items}"
      ],
      "metadata": {
        "id": "uWcB_DgPxaAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simpleStoi = {s:i for i,s in enumerate(alphabet)}\n",
        "simpleItos = {i:s for s,i in simpleStoi.items()}"
      ],
      "metadata": {
        "id": "JbYBR7ZXyFTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for word in names[:1]:\n",
        "  word = ['.'] + ['.'] + list(word) + ['.'] # hallucinating 2 start tokens\n",
        "  for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
        "    ix1 = stoi[ch1 + ch2]\n",
        "    ix2 = simpleStoi[ch3]\n",
        "    N[ix1, ix2] += 1\n",
        "    count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAYK2cCCvM-X",
        "outputId": "f1133fbc-e3c2-4aaf-c216-46b23fb0fb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". e m\n",
            "e m m\n",
            "m m a\n",
            "m a .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pNJnwSlqyk3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (200, 200)) # probs not good figsize\n",
        "plt.imshow(N, cmap = \"Reds\")\n",
        "for i in range(729):\n",
        "  for j in range(27):\n",
        "    chstr = itos[i] + simpleItos[j]\n",
        "    plt.text(j, i, chstr, ha = \"center\", va = \"bottom\", color = \"black\")\n",
        "    plt.text(j, i, N[i][j].item(), ha = \"center\", va = \"top\", color = \"black\")\n",
        "\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "6lwobRkoytJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a probability distribution to sample from w/ model smoothing\n",
        "P = (N + 1).float()\n",
        "P /= P.sum(1, keepdims = True)"
      ],
      "metadata": {
        "id": "MDFL6qMa0BEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cc6zIlhUB2sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P[1].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL4O-H7n5XYC",
        "outputId": "f3c509d3-c0c9-459b-eb6e-3f783f26c8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8YEQhH_7I45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(3)\n",
        "for i in range(10):\n",
        "  i = 0\n",
        "  simpleI = 0\n",
        "  out = []\n",
        "  while True:\n",
        "    p = P[i]\n",
        "    ix = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
        "    # ix can index along columns (27 possibilities)\n",
        "    # must now take 2nd somehow and use it and the ix index to select a new probability distribution\n",
        "    third = simpleItos[ix] # index of new character\n",
        "    if third == '.':\n",
        "      break\n",
        "    second = itos[i][1] # should be the 2nd\n",
        "    i = stoi[second + third]\n",
        "    out.append(third)\n",
        "  print(''.join(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lmf4ujm59zx",
        "outputId": "74566c68-f3c3-4e0b-d203-5a957989bf99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cir\n",
            "anah\n",
            "releemaleeumana\n",
            "olvi\n",
            "siellier\n",
            "lie\n",
            "lychaus\n",
            "riaileile\n",
            "kott\n",
            "kie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now need to calculate loss\n",
        "# calculate average negative log likelihood for whole dataset\n",
        "# take the sum of the logs of the probabilities it assigns to the stuff in the dataset, then negate it, then average it\n",
        "negLogProb = 0\n",
        "totalNames = 0\n",
        "for name in names:\n",
        "  totalNames += 1\n",
        "  name = ['.'] + ['.'] + list(name) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
        "    ix1 = stoi[ch1 + ch2]\n",
        "    ix2 = simpleStoi[ch3]\n",
        "    prob = P[ix1][ix2]\n",
        "    negLogProb -= torch.log(prob)\n",
        "\n",
        "print(f'Average NLL = {negLogProb / totalNames}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHzWU7-c6Te5",
        "outputId": "ed493418-40b5-4423-fdc0-26fdfe98e63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NLL = 15.754159927368164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average NLL = 15.754159927368164"
      ],
      "metadata": {
        "id": "qibESzd2CCTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trigram is worse because it's held to a higher standard??? (best explanation I got, from chatGPT)"
      ],
      "metadata": {
        "id": "C21Kpzkj-I52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E02: Split Dataset**"
      ],
      "metadata": {
        "id": "KOL7rrOoCy4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBxmW-vdCvyc",
        "outputId": "ae5030b6-9aaa-4f9b-9361-88b193193816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK8O8cBDC62z",
        "outputId": "49be02a0-79c3-4ca0-c046-c91a50919116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainIndex = (int) (len(names) * 0.8)"
      ],
      "metadata": {
        "id": "APA0SqA_C8x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testIndex = trainIndex + (int) ((len(names) - trainIndex) / 2)"
      ],
      "metadata": {
        "id": "uwiWFrHpDBI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "AiougHwVDrZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(names[0])\n",
        "random.shuffle(names)\n",
        "print(names[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5tAHkhtDyuy",
        "outputId": "ed435115-5577-4432-aabd-4b43b009c873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tanitoluwa\n",
            "kendrik\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainNames = names[:trainIndex]\n",
        "testNames = names[trainIndex:testIndex]\n",
        "devNames = names[testIndex:]"
      ],
      "metadata": {
        "id": "Zm2PQz9lD6Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros(729, 27)"
      ],
      "metadata": {
        "id": "MSOZpKL1EmiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "stop = (int) (len(trainNames) * 0.6) - 1\n",
        "for word in trainNames[:stop]:\n",
        "  word = ['.'] + ['.'] + list(word) + ['.'] # hallucinating 2 start tokens\n",
        "  for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
        "    ix1 = stoi[ch1 + ch2]\n",
        "    ix2 = simpleStoi[ch3]\n",
        "    N[ix1, ix2] += 1\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "7705pWuTEZSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smoothing = 1\n",
        "P = (N + smoothing).float()\n",
        "P /= P.sum(1, keepdims = True)"
      ],
      "metadata": {
        "id": "_DqMKn96Eqdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OG Average NLL = 15.754159927368164"
      ],
      "metadata": {
        "id": "mLGDYnTwFAkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negLogProb = 0\n",
        "totalNames = 0\n",
        "for name in devNames:\n",
        "  totalNames += 1\n",
        "  name = ['.'] + ['.'] + list(name) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
        "    ix1 = stoi[ch1 + ch2]\n",
        "    ix2 = simpleStoi[ch3]\n",
        "    prob = P[ix1][ix2]\n",
        "    negLogProb -= torch.log(prob)\n",
        "\n",
        "print(f'Average NLL = {negLogProb / totalNames}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzTSdfzfEjDK",
        "outputId": "f5b5e8a4-fab7-4aa0-8719-6771a186ad6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NLL = 16.166526794433594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in trainNames[stop:]:\n",
        "  word = ['.'] + ['.'] + list(word) + ['.'] # hallucinating 2 start tokens\n",
        "  for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
        "    ix1 = stoi[ch1 + ch2]\n",
        "    ix2 = simpleStoi[ch3]\n",
        "    N[ix1, ix2] += 1\n",
        "    count += 1\n",
        "P = (N + smoothing).float()\n",
        "P /= P.sum(1, keepdims = True)"
      ],
      "metadata": {
        "id": "s7S_EWnWGYnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negLogProb = 0\n",
        "totalNames = 0\n",
        "for name in testNames:\n",
        "  totalNames += 1\n",
        "  name = ['.'] + ['.'] + list(name) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(name, name[1:], name[2:]):\n",
        "    ix1 = stoi[ch1 + ch2]\n",
        "    ix2 = simpleStoi[ch3]\n",
        "    prob = P[ix1][ix2]\n",
        "    negLogProb -= torch.log(prob)\n",
        "\n",
        "print(f'Average NLL = {negLogProb / totalNames}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqExtyPJE3I7",
        "outputId": "3e421803-64e1-426d-89b7-5f80c48e8670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average NLL = 15.915894508361816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss decreases slightly after completing training\n",
        "# loss goes up slightly compared to whole dataset training. Implies overfitting to the training data\n",
        "# unclear why it overfits when trained on less data - must not be overfitting"
      ],
      "metadata": {
        "id": "hptS7klcE5fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E03: Smoothing Tuning**"
      ],
      "metadata": {
        "id": "D5JIYTQuFIRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# smoothing = 1: 16.1248\n",
        "# smoothing = 10: 17.406\n",
        "# smoothing = 25: 18.4569\n",
        "# smoothing = 50: 19.4234\n",
        "# smoothing = 100: 20.4277\n",
        "# smoothing = 250: 21.613\n",
        "# smoothing = 500: 22.3040\n",
        "\n",
        "\n",
        "# FOR TRIGRAM, MINIMUM SMOOTHING WAS BEST\n",
        "# SINCE SMOOTHING MIRRORS REGULARIZATION, WOULD LIKELY HAVE SIMILAR RESULTS\n",
        "# Makes sense since model wasn't overfitting"
      ],
      "metadata": {
        "id": "NfNupJZaFMsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtJjkw83Yw9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}